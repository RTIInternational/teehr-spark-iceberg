{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "247fb2ab",
   "metadata": {},
   "source": [
    "### TEEHR with Spark and Iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21cdf61-0056-4208-baf6-8c223d6481a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import duckdb\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f16fa4-e55a-42d7-98f6-bc9457f6798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4230e7f-7edd-4ce2-867a-5dd9e5033387",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"spark.kubernetes.authenticate.driver.serviceAccountName\": \"jupyter\",\n",
    "    \"spark.kubernetes.namespace\": \"teehr-spark-default\",\n",
    "    \"spark.kubernetes.container.image\": os.environ[\"TEEHR_WORKER_IMAGE\"],\n",
    "    \"spark.executor.extraJavaOptions=-Daws.region\": \"us-east-1\",\n",
    "    \"spark.driver.extraJavaOptions=-Daws.region\": \"us-east-1\",\n",
    "    \"spark.executor.instances\": \"6\",\n",
    "    \"spark.executor.memory\": \"16g\",\n",
    "    \"spark.executor.cores\": \"2\",\n",
    "    \"spark.driver.blockManager.port\": \"7777\",\n",
    "    \"spark.driver.port\": \"2222\",\n",
    "    \"spark.driver.host\": \"jupyter.teehr-spark-default.svc.cluster.local\",\n",
    "    \"spark.driver.bindAddress\": \"0.0.0.0\",\n",
    "    \"spark.hadoop.fs.s3a.impl\": \"org.apache.hadoop.fs.s3a.S3AFileSystem\",\n",
    "    \"spark.hadoop.fs.s3a.aws.credentials.provider\": \"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\",\n",
    "    \"spark.sql.catalog.demo.s3.access-key-id\": \"minio\",\n",
    "    \"spark.sql.catalog.demo.s3.secret-access-key\": \"password123\",\n",
    "    \"spark.sql.parquet.enableVectorizedReader\": \"false\",\n",
    "    \"spark.kubernetes.executor.node.selector.dedicated\": \"worker\",\n",
    "    \"spark.kubernetes.executor.podTemplateFile\": \"/home/spark/pod-template.yaml\",\n",
    "}\n",
    "\n",
    "def get_spark_session(app_name: str, conf: SparkConf):\n",
    "    conf.setMaster(\"k8s://https://kubernetes.default.svc.cluster.local\")\n",
    "    for key, value in config.items():\n",
    "        conf.set(key, value)    \n",
    "    return SparkSession.builder.appName(app_name).config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aebae7c-bfdd-4074-b688-e3e5abbbd6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/19 17:56:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/19 17:56:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = get_spark_session(\"teehr-workers\", SparkConf())\n",
    "# spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e11961f6-79fc-4e24-bdeb-0d6c6163144a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|         value_time|             value|\n",
      "+-------------------+------------------+\n",
      "|2016-01-01 00:00:00|1.4215056896209717|\n",
      "|2016-01-01 01:00:00|1.4215056896209717|\n",
      "|2016-01-01 02:00:00|1.3903571367263794|\n",
      "|2016-01-01 03:00:00|1.3903571367263794|\n",
      "|2016-01-01 04:00:00| 1.359208583831787|\n",
      "|2016-01-01 05:00:00| 1.359208583831787|\n",
      "|2016-01-01 06:00:00|1.3280601501464844|\n",
      "|2016-01-01 07:00:00|1.3280601501464844|\n",
      "|2016-01-01 08:00:00|1.2969114780426025|\n",
      "|2016-01-01 09:00:00|1.2969114780426025|\n",
      "|2016-01-01 10:00:00|1.2657630443572998|\n",
      "|2016-01-01 11:00:00|1.2657630443572998|\n",
      "|2016-01-01 12:00:00|1.2346144914627075|\n",
      "|2016-01-01 13:00:00|1.2346144914627075|\n",
      "|2016-01-01 14:00:00|1.2062976360321045|\n",
      "|2016-01-01 15:00:00|1.2062976360321045|\n",
      "|2016-01-01 16:00:00|1.2062976360321045|\n",
      "|2016-01-01 17:00:00|1.1751490831375122|\n",
      "|2016-01-01 18:00:00|1.1751490831375122|\n",
      "|2016-01-01 19:00:00|1.1751490831375122|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 6.39 ms, sys: 1.38 ms, total: 7.76 ms\n",
      "Wall time: 7.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spark.sql(\"SELECT value_time, value FROM science_eval.primary WHERE location_id = 'usgs-01116905' ORDER BY value_time;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6d1ab13-1e18-4f68-9705-6f221175071a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.udf.UserDefinedFunction at 0x7f0575e024d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas_udfs import * \n",
    "spark.udf.register(\"teehr_kling_gupta_efficiency\", teehr_kling_gupta_efficiency)\n",
    "spark.udf.register(\"teehr_root_mean_squared_error\", teehr_root_mean_squared_error)\n",
    "spark.udf.register(\"teehr_relative_bias\", teehr_relative_bias)\n",
    "spark.udf.register(\"teehr_r_squared\", teehr_r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d5a744-3df4-4ef3-ad6c-d42c6984e698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:========================================================>(71 + 1) / 72]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------+-----------------------+-------------+-----------+\n",
      "|primary_location_id|kling_gupta_efficiency|root_mean_squared_error|relative_bias|  r_squared|\n",
      "+-------------------+----------------------+-----------------------+-------------+-----------+\n",
      "|      usgs-01010000|            0.42462006|               97.13046|  -0.21570142|  0.7913283|\n",
      "|      usgs-01010070|            0.44942167|              14.033999|  -0.28686345|  0.6007537|\n",
      "|      usgs-01010500|            0.27008578|              221.87845|   -0.3975725|  0.8074171|\n",
      "|      usgs-01011000|             0.6334492|              57.011288|  -0.19466422|  0.7688364|\n",
      "|      usgs-01013500|            0.54683834|              41.360138|  -0.23086037| 0.82660383|\n",
      "|      usgs-01014000|            0.37036315|              354.70465|  -0.35600448| 0.86370957|\n",
      "|      usgs-01015800|            0.72119784|              31.359137|  -0.14541015| 0.90401065|\n",
      "|      usgs-01017000|            0.76449686|              57.808865|  -0.09843478|  0.8892501|\n",
      "|      usgs-01017060|             0.6873559|              0.5079917|   0.07933129|  0.5164445|\n",
      "|      usgs-01017290|             0.4168857|              18.884745|  -0.21996878|  0.6675259|\n",
      "|      usgs-01017550|            0.42698726|              0.4415826|   0.41983798| 0.52192134|\n",
      "|      usgs-01017960|            0.67964256|               4.262498|  -0.21201137| 0.81922287|\n",
      "|      usgs-01018009|              0.769888|             0.44256148|   0.14787525|  0.6831904|\n",
      "|      usgs-01018035|            0.67143023|              11.717031|   -0.1973257| 0.84843445|\n",
      "|      usgs-01018500|            0.18728177|               22.00335|   -0.5378539|  0.2678657|\n",
      "|      usgs-01019000|           -0.20420341|               9.898839|  -0.59008384|  0.2126098|\n",
      "|      usgs-01021000|            0.39480862|              49.391823|  -0.39673087|  0.7035693|\n",
      "|      usgs-01021470|            0.36194548|             0.40687102|  -0.10617435|  0.5188219|\n",
      "|      usgs-01021480|             0.6604273|              1.1185906|   -0.1908394| 0.73515147|\n",
      "|      usgs-01022294|           -0.12970932|            0.014386292|   0.72382146|0.062768936|\n",
      "+-------------------+----------------------+-----------------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 74.2 ms, sys: 21.7 ms, total: 96 ms\n",
      "Wall time: 51.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sdf = spark.sql(\"\"\"\n",
    "WITH metrics AS (\n",
    "    SELECT\n",
    "        joined.primary_location_id\n",
    "        , teehr_kling_gupta_efficiency(joined.primary_value, joined.secondary_value) as kling_gupta_efficiency\n",
    "        , teehr_root_mean_squared_error(joined.primary_value, joined.secondary_value) as root_mean_squared_error\n",
    "        , teehr_relative_bias(joined.primary_value, joined.secondary_value) as relative_bias\n",
    "        , teehr_r_squared(joined.primary_value, joined.secondary_value) as r_squared\n",
    "    FROM\n",
    "        science_eval.joined as joined\n",
    "    GROUP BY\n",
    "        joined.primary_location_id\n",
    ")\n",
    "SELECT\n",
    "    metrics.primary_location_id\n",
    "    , kling_gupta_efficiency\n",
    "    , root_mean_squared_error\n",
    "    , relative_bias\n",
    "    , r_squared\n",
    "FROM metrics\n",
    "ORDER BY\n",
    "    metrics.primary_location_id;\n",
    "\"\"\")\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a30826c-2bca-4cf4-9854-28f1b30175fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:==================================================>   (187 + 12) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------+-----------------------+-------------+----------+\n",
      "|primary_location_id|kling_gupta_efficiency|root_mean_squared_error|relative_bias| r_squared|\n",
      "+-------------------+----------------------+-----------------------+-------------+----------+\n",
      "|      usgs-01021480|             0.6604273|              1.1185906|   -0.1908394|0.73515147|\n",
      "+-------------------+----------------------+-----------------------+-------------+----------+\n",
      "\n",
      "CPU times: user 10 ms, sys: 3.27 ms, total: 13.3 ms\n",
      "Wall time: 4.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sdf = spark.sql(\"\"\"\n",
    "WITH metrics AS (\n",
    "    SELECT\n",
    "        joined.primary_location_id\n",
    "        , teehr_kling_gupta_efficiency(joined.primary_value, joined.secondary_value) as kling_gupta_efficiency\n",
    "        , teehr_root_mean_squared_error(joined.primary_value, joined.secondary_value) as root_mean_squared_error\n",
    "        , teehr_relative_bias(joined.primary_value, joined.secondary_value) as relative_bias\n",
    "        , teehr_r_squared(joined.primary_value, joined.secondary_value) as r_squared\n",
    "    FROM\n",
    "        science_eval.joined as joined\n",
    "    GROUP BY\n",
    "        joined.primary_location_id\n",
    ")\n",
    "SELECT\n",
    "    metrics.primary_location_id\n",
    "    , kling_gupta_efficiency\n",
    "    , root_mean_squared_error\n",
    "    , relative_bias\n",
    "    , r_squared\n",
    "FROM metrics\n",
    "WHERE\n",
    "    primary_location_id='usgs-01021480'\n",
    "ORDER BY\n",
    "    metrics.primary_location_id;\n",
    "\"\"\")\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "934183bc-3f9a-46bb-922c-34843e06f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/19 17:57:20 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a50f85-8a24-4df1-8a90-0a66329e2581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
