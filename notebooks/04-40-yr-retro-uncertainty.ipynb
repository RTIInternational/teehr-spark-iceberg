{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d849a11-e129-4638-8a2d-3c61d6791899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from arch.bootstrap import StationaryBootstrap\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType, MapType, StructType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e689fd-d0f1-48ca-8fce-c7437f261802",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"spark.kubernetes.authenticate.driver.serviceAccountName\": \"jupyter\",\n",
    "    \"spark.kubernetes.namespace\": \"teehr-spark-default\",\n",
    "    \"spark.kubernetes.container.image\": os.environ[\"TEEHR_WORKER_IMAGE\"],\n",
    "    \"spark.executor.extraJavaOptions=-Daws.region\": \"us-east-1\",\n",
    "    \"spark.driver.extraJavaOptions=-Daws.region\": \"us-east-1\",\n",
    "    \"spark.executor.instances\": \"2\",\n",
    "    \"spark.executor.memory\": \"4g\",\n",
    "    \"spark.executor.cores\": \"2\",\n",
    "    \"spark.driver.blockManager.port\": \"7777\",\n",
    "    \"spark.driver.port\": \"2222\",\n",
    "    \"spark.driver.host\": \"jupyter.teehr-spark-default.svc.cluster.local\",\n",
    "    \"spark.driver.bindAddress\": \"0.0.0.0\",\n",
    "    \"spark.hadoop.fs.s3a.impl\": \"org.apache.hadoop.fs.s3a.S3AFileSystem\",\n",
    "    \"spark.hadoop.fs.s3a.aws.credentials.provider\": \"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\",\n",
    "    \"spark.sql.catalog.demo.s3.access-key-id\": \"minio\",\n",
    "    \"spark.sql.catalog.demo.s3.secret-access-key\": \"password123\",\n",
    "    \"spark.sql.parquet.enableVectorizedReader\": \"false\",\n",
    "    \"spark.kubernetes.executor.node.selector.dedicated\": \"worker-cpu\",\n",
    "    \"spark.kubernetes.executor.podTemplateFile\": \"/home/spark/pod-template.yaml\",\n",
    "    \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
    "}\n",
    "\n",
    "def get_spark_session(app_name: str, conf: SparkConf):\n",
    "    conf.setMaster(\"k8s://https://kubernetes.default.svc.cluster.local\")\n",
    "    for key, value in config.items():\n",
    "        conf.set(key, value)    \n",
    "    return SparkSession.builder.appName(app_name).config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9ba62-a6bb-4cab-a27c-b74ec3992229",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = get_spark_session(\"teehr-workers\", SparkConf())\n",
    "# spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00343b08-2032-4b99-b1d4-977a7aff3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkSession.builder.master(\"local[*]\").getOrCreate().stop()\n",
    "\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setAppName('TestJupyter')\n",
    "    .set(\"spark.sql.catalog.demo.s3.access-key-id\", \"minio\")\n",
    "    .set(\"spark.sql.catalog.demo.s3.secret-access-key\", \"password123\")\n",
    ")\n",
    "## Start Spark Session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "# spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7479a1b-bb89-49ca-a0d5-31442c6c067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE = \"streamflow\"\n",
    "PRIMARY_TABLE = \"primary\"\n",
    "SECONDARY_TABLE = \"secondary\"\n",
    "CROSSWALK_TABLE = \"crosswalk\"\n",
    "JOINED_TABLE = \"joined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24493239-a8ee-4f96-9971-4834e0c512c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kling_gupta_efficiency(p: pd.Series, s: pd.Series) -> float:\n",
    "    \n",
    "    if len(s) == 0 or len(s) == 0:\n",
    "        return np.nan\n",
    "    std_p = np.std(p)\n",
    "    mean_p = np.mean(p)\n",
    "    std_s = np.std(s)\n",
    "\n",
    "    if std_p == 0 or mean_p == 0 or std_s == 0:\n",
    "        return np.nan\n",
    "        \n",
    "    # Pearson correlation coefficient\n",
    "    linear_correlation = np.corrcoef(s, p)[0,1]\n",
    "\n",
    "    # Relative variability\n",
    "    relative_variability = std_s / std_p\n",
    "\n",
    "    # Relative mean\n",
    "    relative_mean = np.mean(s) / mean_p\n",
    "\n",
    "    # Scaled Euclidean distance\n",
    "    euclidean_distance = np.sqrt(\n",
    "        (1 * (linear_correlation - 1.0)) ** 2.0 + \n",
    "        (1 * (relative_variability - 1.0)) ** 2.0 + \n",
    "        (1* (relative_mean - 1.0)) ** 2.0\n",
    "        )\n",
    "\n",
    "    # Return KGE\n",
    "    return 1.0 - euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c6ee56-be00-42a2-aa36-65c65f9bce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf( MapType(StringType(), FloatType()) )\n",
    "def bs_kling_gupta_efficiency(p: pd.Series, s: pd.Series) -> float:\n",
    "    \n",
    "    bs = StationaryBootstrap(365, p, s, seed=1234)\n",
    "    results = bs.apply(kling_gupta_efficiency, 1000)\n",
    "    quantiles = (0.05, 0.50, 0.95)\n",
    "    values = np.quantile(results, quantiles)\n",
    "    quantiles = [f\"KGE_{str(i)}\" for i in quantiles]\n",
    "    d = dict(zip(quantiles,values))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286ed36-c937-4666-94ca-b6882fc04d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.udf.register(\"bs_kling_gupta_efficiency\", bs_kling_gupta_efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1dc75-08ca-42b8-84f6-5e8cbb24a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate a few basic metrics for python UFDs\n",
    "sdf = spark.sql(f\"\"\"\n",
    "WITH joined as (\n",
    "    SELECT * FROM {DATABASE}.{JOINED_TABLE}\n",
    ")\n",
    ", metrics AS (\n",
    "    SELECT\n",
    "        joined.primary_location_id\n",
    "        , bs_kling_gupta_efficiency(joined.primary_value, joined.secondary_value) as bs_kling_gupta_efficiency\n",
    "    FROM\n",
    "        joined\n",
    "    GROUP BY\n",
    "        joined.primary_location_id\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM metrics\n",
    "  -- WHERE primary_location_id IN ('usgs-01010070', 'usgs-01105500')\n",
    "ORDER BY\n",
    "    metrics.primary_location_id\n",
    "\"\"\")\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccc0c06-c655-44a5-ba69-c9bc69acbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = spark.read.parquet(\"s3a://ciroh-rti-public-data/teehr-data-warehouse/common/observations/usgs_conus/streamflow_hourly_inst/*.parquet\")\n",
    "sim = spark.read.parquet(\"s3a://ciroh-rti-public-data/teehr-data-warehouse/common/baselines/nwm30_retrospective_conus/streamflow_hourly_inst/*.parquet\")\n",
    "xw = spark.read.parquet(\"s3a://ciroh-rti-public-data/teehr-data-warehouse/common/crosswalks/usgs_nwm30_crosswalk.conus.parquet\")\n",
    "\n",
    "obs.createTempView(\"obs_temp\")\n",
    "sim.createTempView(\"sim_temp\")\n",
    "xw.createTempView(\"xw_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0906c58-4979-4d1f-bddd-24857361dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate a few basic metrics for python UFDs\n",
    "sdf = spark.sql(f\"\"\"\n",
    "WITH joined as (\n",
    "    SELECT\n",
    "        sf.reference_time\n",
    "        , sf.value_time as value_time\n",
    "        , sf.location_id as secondary_location_id\n",
    "        , pf.reference_time as reference_time\n",
    "        , sf.value as secondary_value\n",
    "        , sf.configuration\n",
    "        , sf.measurement_unit\n",
    "        , sf.variable_name\n",
    "        , pf.value as primary_value\n",
    "        , pf.location_id as primary_location_id\n",
    "    FROM sim_temp sf\n",
    "    JOIN xw_temp cf\n",
    "        on cf.secondary_location_id = sf.location_id\n",
    "    JOIN obs_temp pf\n",
    "        on cf.primary_location_id = pf.location_id\n",
    "        and sf.value_time = pf.value_time\n",
    "        and sf.measurement_unit = pf.measurement_unit\n",
    "        and sf.variable_name = pf.variable_name\n",
    ")\n",
    ", metrics AS (\n",
    "    SELECT\n",
    "        joined.primary_location_id\n",
    "        , bs_kling_gupta_efficiency(joined.primary_value, joined.secondary_value) as bs_kling_gupta_efficiency\n",
    "    FROM\n",
    "        joined\n",
    "    GROUP BY\n",
    "        joined.primary_location_id\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM metrics\n",
    "  -- WHERE primary_location_id IN ('usgs-01010070', 'usgs-01105500')\n",
    "ORDER BY\n",
    "    metrics.primary_location_id\n",
    "\"\"\")\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd1d67-b871-4895-a17e-8e572f51c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb54e1-ed3c-4487-8f2e-a75548f57be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
